{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lee Cheng Hui\n",
    "17204205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Import regular expressions to process emails\n",
    "import re\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianKernel(x1, x2, sigma):\n",
    "    \"\"\"\n",
    "    Computes the radial basis function\n",
    "    Returns a radial basis function kernel between x1 and x2.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x1 :  numpy ndarray\n",
    "        A vector of size (n, ), representing the first datapoint.\n",
    "    \n",
    "    x2 : numpy ndarray\n",
    "        A vector of size (n, ), representing the second datapoint.\n",
    "    \n",
    "    sigma : float\n",
    "        The bandwidth parameter for the Gaussian kernel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sim : float\n",
    "        The computed RBF between the two provided data points.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to return the similarity between `x1` and `x2`\n",
    "    computed using a Gaussian kernel with bandwidth `sigma`.\n",
    "    \"\"\"\n",
    "    sim = np.exp(-np.sum(np.square(x1 - x2))/(2*sigma*sigma))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "## 2 Spam Classification\n",
    "\n",
    "Many email services today provide spam filters that are able to classify emails into spam and non-spam email with high accuracy. In this part of the exercise, you will use SVMs to build your own spam filter.\n",
    "\n",
    "You will be training a classifier to classify whether a given email, $x$, is spam ($y = 1$) or non-spam ($y = 0$). In particular, you need to convert each email into a feature vector $x \\in \\mathbb{R}^n$ . The following parts of the exercise will walk you through how such a feature vector can be constructed from an email.\n",
    "\n",
    "The dataset included for this exercise is based on a a subset of the [SpamAssassin Public Corpus](http://spamassassin.apache.org/old/publiccorpus/). For the purpose of this exercise, you will only be using the body of the email (excluding the email headers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEmail(email_contents, verbose=True):\n",
    "    \"\"\"\n",
    "    Preprocesses the body of an email and returns a list of indices \n",
    "    of the words contained in the email.    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    email_contents : str\n",
    "        A string containing one email. \n",
    "    \n",
    "    verbose : bool\n",
    "        If True, print the resulting email after processing.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    word_indices : list\n",
    "        A list of integers containing the index of each word in the \n",
    "        email which is also present in the vocabulary.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to add the index of word to word_indices \n",
    "    if it is in the vocabulary. At this point of the code, you have \n",
    "    a stemmed word from the email in the variable word.\n",
    "    You should look up word in the vocabulary list (vocabList). \n",
    "    If a match exists, you should add the index of the word to the word_indices\n",
    "    list. Concretely, if word = 'action', then you should\n",
    "    look up the vocabulary list to find where in vocabList\n",
    "    'action' appears. For example, if vocabList[18] =\n",
    "    'action', then, you should add 18 to the word_indices \n",
    "    vector (e.g., word_indices.append(18)).\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - vocabList[idx] returns a the word with index idx in the vocabulary list.\n",
    "    \n",
    "    - vocabList.index(word) return index of word `word` in the vocabulary list.\n",
    "      (A ValueError exception is raised if the word does not exist.)\n",
    "    \"\"\"\n",
    "    # Load Vocabulary\n",
    "    vocabList = utils.getVocabList()\n",
    "\n",
    "    # Init return value\n",
    "    word_indices = []\n",
    "\n",
    "    # ========================== Preprocess Email ===========================\n",
    "    # Find the Headers ( \\n\\n and remove )\n",
    "    # Uncomment the following lines if you are working with raw emails with the\n",
    "    # full headers\n",
    "    # hdrstart = email_contents.find(chr(10) + chr(10))\n",
    "    # email_contents = email_contents[hdrstart:]\n",
    "\n",
    "    # Lower case\n",
    "    email_contents = email_contents.lower()\n",
    "    \n",
    "    # Strip all HTML\n",
    "    # Looks for any expression that starts with < and ends with > and replace\n",
    "    # and does not have any < or > in the tag it with a space\n",
    "    email_contents =re.compile('<[^<>]+>').sub(' ', email_contents)\n",
    "\n",
    "    # Handle Numbers\n",
    "    # Look for one or more characters between 0-9\n",
    "    email_contents = re.compile('[0-9]+').sub(' number ', email_contents)\n",
    "\n",
    "    # Handle URLS\n",
    "    # Look for strings starting with http:// or https://\n",
    "    email_contents = re.compile('(http|https)://[^\\s]*').sub(' httpaddr ', email_contents)\n",
    "\n",
    "    # Handle Email Addresses\n",
    "    # Look for strings with @ in the middle\n",
    "    email_contents = re.compile('[^\\s]+@[^\\s]+').sub(' emailaddr ', email_contents)\n",
    "    \n",
    "    # Handle $ sign\n",
    "    email_contents = re.compile('[$]+').sub(' dollar ', email_contents)\n",
    "    \n",
    "    # get rid of any punctuation\n",
    "    email_contents = re.split('[ @$/#.-:&*+=\\[\\]?!(){},''\">_<;%\\n\\r]', email_contents)\n",
    "\n",
    "    # remove any empty word string\n",
    "    email_contents = [word for word in email_contents if len(word) > 0]\n",
    "    \n",
    "    # Stem the email contents word by word\n",
    "    stemmer = utils.PorterStemmer()\n",
    "    processed_email = []\n",
    "    for word in email_contents:\n",
    "        # Remove any remaining non alphanumeric characters in word\n",
    "        word = re.compile('[^a-zA-Z0-9]').sub('', word).strip()\n",
    "        word = stemmer.stem(word)\n",
    "        processed_email.append(word)\n",
    "\n",
    "        if len(word) < 1:\n",
    "            continue\n",
    "\n",
    "        # Look up the word in the dictionary and add to word_indices if found\n",
    "        # ====================== YOUR CODE HERE ======================\n",
    "        try:\n",
    "            idx = vocabList.index(word)\n",
    "            word_indices.append(idx)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "\n",
    "        # =============================================================\n",
    "\n",
    "    if verbose:\n",
    "        print('----------------')\n",
    "        print('Processed email:')\n",
    "        print('----------------')\n",
    "        print(' '.join(processed_email))\n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Processed email:\n",
      "----------------\n",
      "anyon know how much it cost to host a web portal well it depend on how mani visitor your expect thi can be anywher from less than number buck a month to a coupl of dollar number you should checkout httpaddr or perhap amazon ec number if your run someth big to unsubscrib yourself from thi mail list send an email to emailaddr\n",
      "-------------\n",
      "Word Indices:\n",
      "-------------\n",
      "[85, 915, 793, 1076, 882, 369, 1698, 789, 1821, 1830, 882, 430, 1170, 793, 1001, 1894, 591, 1675, 237, 161, 88, 687, 944, 1662, 1119, 1061, 1698, 374, 1161, 476, 1119, 1892, 1509, 798, 1181, 1236, 511, 1119, 809, 1894, 1439, 1546, 180, 1698, 1757, 1895, 687, 1675, 991, 960, 1476, 70, 529, 1698, 530]\n"
     ]
    }
   ],
   "source": [
    "#  To use an SVM to classify emails into Spam v.s. Non-Spam, you first need\n",
    "#  to convert each email into a vector of features. In this part, you will\n",
    "#  implement the preprocessing steps for each email. You should\n",
    "#  complete the code in processEmail.m to produce a word indices vector\n",
    "#  for a given email.\n",
    "\n",
    "# Extract Features\n",
    "with open(os.path.join('Data', 'emailSample1.txt')) as fid:\n",
    "    file_contents = fid.read()\n",
    "\n",
    "word_indices  = processEmail(file_contents)\n",
    "\n",
    "#Print Stats\n",
    "print('-------------')\n",
    "print('Word Indices:')\n",
    "print('-------------')\n",
    "print(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailFeatures(word_indices):\n",
    "    \"\"\"\n",
    "    Takes in a word_indices vector and produces a feature vector from the word indices. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word_indices : list\n",
    "        A list of word indices from the vocabulary list.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x : list \n",
    "        The computed feature vector.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to return a feature vector for the\n",
    "    given email (word_indices). To help make it easier to  process \n",
    "    the emails, we have have already pre-processed each email and converted\n",
    "    each word in the email into an index in a fixed dictionary (of 1899 words).\n",
    "    The variable `word_indices` contains the list of indices of the words \n",
    "    which occur in one email.\n",
    "    \n",
    "    Concretely, if an email has the text:\n",
    "\n",
    "        The quick brown fox jumped over the lazy dog.\n",
    "\n",
    "    Then, the word_indices vector for this text might look  like:\n",
    "               \n",
    "        60  100   33   44   10     53  60  58   5\n",
    "\n",
    "    where, we have mapped each word onto a number, for example:\n",
    "\n",
    "        the   -- 60\n",
    "        quick -- 100\n",
    "        ...\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    The above numbers are just an example and are not the actual mappings.\n",
    "\n",
    "    Your task is take one such `word_indices` vector and construct\n",
    "    a binary feature vector that indicates whether a particular\n",
    "    word occurs in the email. That is, x[i] = 1 when word i\n",
    "    is present in the email. Concretely, if the word 'the' (say,\n",
    "    index 60) appears in the email, then x[60] = 1. The feature\n",
    "    vector should look like:\n",
    "        x = [ 0 0 0 0 1 0 0 0 ... 0 0 0 0 1 ... 0 0 0 1 0 ..]\n",
    "    \"\"\"\n",
    "    # Total number of words in the dictionary\n",
    "    n = 1899\n",
    "\n",
    "    # You need to return the following variables correctly.\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    # ===================== YOUR CODE HERE ======================\n",
    "    for num in word_indices:\n",
    "        x[num] = 1\n",
    "    \n",
    "    \n",
    "    # ===========================================================\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Processed email:\n",
      "----------------\n",
      "anyon know how much it cost to host a web portal well it depend on how mani visitor your expect thi can be anywher from less than number buck a month to a coupl of dollar number you should checkout httpaddr or perhap amazon ec number if your run someth big to unsubscrib yourself from thi mail list send an email to emailaddr\n",
      "\n",
      "Length of feature vector: 1899\n",
      "Number of non-zero entries: 45\n"
     ]
    }
   ],
   "source": [
    "# Extract Features\n",
    "with open(os.path.join('Data', 'emailSample1.txt')) as fid:\n",
    "    file_contents = fid.read()\n",
    "\n",
    "word_indices  = processEmail(file_contents)\n",
    "features      = emailFeatures(word_indices)\n",
    "\n",
    "# Print Stats\n",
    "print('\\nLength of feature vector: %d' % len(features))\n",
    "print('Number of non-zero entries: %d' % sum(features > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM (Spam Classification)\n",
      "This may take 1 to 2 minutes ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Spam Email dataset\n",
    "# You will have X, y in your environment\n",
    "data = loadmat(os.path.join('Data', 'spamTrain.mat'))\n",
    "X, y= data['X'].astype(float), data['y'][:, 0]\n",
    "\n",
    "print('Training Linear SVM (Spam Classification)')\n",
    "print('This may take 1 to 2 minutes ...\\n')\n",
    "\n",
    "C = 0.1\n",
    "model = utils.svmTrain(X, y, C, utils.linearKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]]),\n",
       " 'y': array([-1,  1, -1, -1,  1,  1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,\n",
       "        -1,  1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1,  1,  1,  1, -1,  1,\n",
       "        -1,  1,  1, -1,  1, -1,  1,  1, -1,  1, -1,  1, -1, -1,  1, -1,  1,\n",
       "        -1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1, -1, -1,\n",
       "        -1, -1, -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1, -1,  1,  1,\n",
       "        -1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1,\n",
       "         1, -1, -1,  1, -1,  1, -1, -1,  1,  1,  1,  1, -1,  1, -1,  1, -1,\n",
       "        -1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1,\n",
       "        -1, -1,  1, -1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,  1, -1,\n",
       "        -1,  1, -1,  1,  1,  1, -1, -1,  1,  1, -1,  1,  1, -1, -1, -1, -1,\n",
       "         1, -1,  1, -1, -1, -1,  1,  1, -1, -1,  1,  1, -1, -1, -1,  1, -1,\n",
       "         1, -1, -1,  1, -1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1,  1,\n",
       "         1, -1,  1,  1, -1, -1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1, -1,\n",
       "         1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1,  1,\n",
       "         1, -1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1,  1,  1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1,  1,  1, -1, -1,  1,\n",
       "        -1, -1, -1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1, -1, -1,  1, -1,\n",
       "         1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1,\n",
       "         1, -1, -1, -1, -1, -1,  1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1,\n",
       "        -1, -1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "         1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1, -1,  1,  1,  1, -1, -1,\n",
       "         1, -1, -1,  1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1,\n",
       "        -1,  1, -1, -1, -1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1, -1,  1,\n",
       "        -1, -1, -1,  1, -1, -1,  1, -1,  1, -1, -1, -1,  1,  1, -1, -1,  1,\n",
       "        -1,  1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1,\n",
       "         1,  1, -1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1, -1,\n",
       "        -1,  1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1,\n",
       "        -1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1,\n",
       "        -1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1,  1,  1, -1,\n",
       "         1,  1,  1,  1,  1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1,  1,  1,\n",
       "         1, -1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1,\n",
       "         1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        -1, -1, -1,  1, -1,  1, -1, -1,  1, -1, -1, -1,  1, -1,  1, -1, -1,\n",
       "        -1, -1, -1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1,  1,\n",
       "         1, -1, -1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1,  1,  1, -1,  1,\n",
       "        -1,  1,  1, -1, -1, -1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1,  1,\n",
       "         1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1,  1,  1, -1, -1,\n",
       "         1, -1, -1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1, -1, -1,\n",
       "        -1, -1, -1, -1,  1,  1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,\n",
       "         1,  1, -1,  1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1, -1, -1,  1,\n",
       "        -1, -1, -1, -1,  1, -1,  1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
       "        -1, -1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1,  1,  1, -1, -1,  1, -1, -1, -1,  1,  1, -1,\n",
       "        -1,  1, -1,  1, -1,  1, -1, -1, -1,  1, -1, -1,  1,  1, -1, -1,  1,\n",
       "         1,  1,  1,  1,  1, -1, -1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,\n",
       "         1,  1, -1, -1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1, -1,  1,  1,\n",
       "         1,  1, -1,  1,  1,  1,  1,  1, -1, -1]),\n",
       " 'kernelFunction': <function utils.linearKernel(x1, x2)>,\n",
       " 'b': 0.22488717246974013,\n",
       " 'args': (),\n",
       " 'alphas': array([9.42116111e-03, 8.67361738e-19, 8.67361738e-19, 6.95504283e-04,\n",
       "        9.41255205e-04, 1.21605568e-03, 8.24886854e-04, 1.64737400e-02,\n",
       "        3.74465113e-02, 4.52164105e-02, 5.00995801e-02, 7.18296002e-03,\n",
       "        2.84075250e-04, 6.22350319e-02, 1.00107967e-02, 6.64505774e-03,\n",
       "        1.00000000e-01, 3.08531841e-02, 3.92722413e-03, 3.47887381e-03,\n",
       "        4.56359978e-04, 6.32355301e-02, 5.42805698e-02, 4.33680869e-19,\n",
       "        3.10421970e-03, 4.33680869e-19, 5.28243880e-04, 2.79533031e-03,\n",
       "        8.54713581e-05, 6.34003098e-04, 1.94912812e-02, 5.20105932e-03,\n",
       "        8.67361738e-19, 3.05698429e-03, 1.03891739e-02, 7.01263776e-04,\n",
       "        2.44698976e-02, 1.00000000e-01, 1.46413793e-04, 6.42482086e-04,\n",
       "        2.57393259e-04, 8.69664182e-02, 8.23925114e-03, 9.94260985e-04,\n",
       "        4.33680869e-19, 1.58649144e-02, 7.21344690e-07, 3.23262703e-04,\n",
       "        7.67077171e-04, 1.73472348e-18, 4.24285633e-03, 5.20417043e-18,\n",
       "        5.99696350e-04, 2.45170485e-02, 1.00000000e-01, 3.11227559e-03,\n",
       "        6.40175714e-04, 1.31951569e-03, 8.92701755e-03, 9.84484310e-05,\n",
       "        1.96358785e-02, 3.29217777e-03, 1.89805430e-02, 2.06196537e-02,\n",
       "        1.39755813e-02, 1.14624963e-02, 3.13055335e-02, 2.39042166e-02,\n",
       "        1.69092237e-02, 6.35407112e-02, 1.00000000e-01, 4.45417392e-02,\n",
       "        5.02195821e-04, 4.62062677e-02, 5.49176751e-03, 1.00000000e-01,\n",
       "        1.91541222e-04, 5.58940175e-02, 1.30104261e-18, 7.16421438e-04,\n",
       "        1.71738439e-04, 5.46939656e-02, 5.61088185e-04, 6.61164494e-03,\n",
       "        1.27508074e-03, 3.27854125e-02, 1.40440095e-03, 4.51022755e-03,\n",
       "        1.44454589e-02, 3.41787538e-04, 1.69260484e-02, 3.28571628e-04,\n",
       "        4.08683426e-03, 4.15356929e-02, 1.01294314e-02, 2.24497751e-03,\n",
       "        2.85214554e-04, 7.75668978e-03, 1.76869861e-02, 3.56112405e-04,\n",
       "        2.05462928e-03, 1.75167401e-04, 8.67361738e-19, 9.00832825e-04,\n",
       "        7.29990484e-02, 2.01494702e-02, 2.84197523e-02, 6.75574457e-04,\n",
       "        2.16840434e-19, 4.33680869e-19, 2.31435332e-03, 8.80977374e-04,\n",
       "        6.53430852e-04, 5.67076920e-03, 9.20305116e-04, 1.43111240e-02,\n",
       "        9.51340796e-04, 8.65996437e-02, 9.80744837e-04, 4.19700785e-03,\n",
       "        9.33674160e-02, 8.88198719e-04, 1.17812495e-02, 9.36387764e-02,\n",
       "        9.54007774e-04, 1.00000000e-01, 4.01475559e-02, 2.51610761e-04,\n",
       "        6.59673893e-04, 2.72663651e-03, 8.55416154e-05, 1.60408244e-02,\n",
       "        4.91323291e-02, 1.00000000e-01, 3.98077466e-04, 1.02168451e-04,\n",
       "        1.16078242e-03, 2.65414245e-02, 1.00000000e-01, 4.47845240e-02,\n",
       "        1.39454372e-02, 1.06897186e-03, 3.55859470e-04, 2.50050726e-03,\n",
       "        4.03181061e-03, 9.97758257e-02, 4.54116023e-02, 1.02643929e-04,\n",
       "        3.43692916e-03, 1.00000000e-01, 1.49684140e-03, 6.85281146e-03,\n",
       "        7.23667780e-03, 5.32508341e-02, 1.00000000e-01, 3.61398878e-04,\n",
       "        2.68637175e-02, 7.20454615e-05, 6.09661912e-02, 2.16840434e-18,\n",
       "        6.65195954e-02, 5.29549415e-02, 2.47469415e-02, 3.07604539e-04,\n",
       "        8.67361738e-19, 2.23933465e-03, 2.61842888e-02, 4.02477743e-03,\n",
       "        3.51909851e-03, 8.67361738e-19, 3.68217303e-03, 8.32515298e-03,\n",
       "        7.35604287e-04, 1.12856625e-02, 2.86473320e-04, 7.54743582e-04,\n",
       "        1.00000000e-01, 7.98793242e-03, 5.30453602e-02, 4.52280236e-02,\n",
       "        3.15765447e-02, 2.44923837e-02, 1.43377986e-02, 2.72369102e-02,\n",
       "        1.95254790e-02, 6.14366960e-03, 9.95541495e-04, 1.14139378e-02,\n",
       "        1.00000000e-01, 2.28020479e-04, 2.25422172e-02, 5.67340732e-02,\n",
       "        1.96184075e-02, 1.08984899e-02, 1.00000000e-01, 3.50751260e-02,\n",
       "        9.99547262e-02, 1.53138379e-03, 1.00000000e-01, 2.55984342e-03,\n",
       "        1.00000000e-01, 1.00000000e-01, 1.00000000e-01, 2.34608347e-03,\n",
       "        1.02184166e-02, 2.32509393e-02, 1.15895107e-03, 8.03901888e-04,\n",
       "        3.72983158e-02, 3.48028189e-02, 5.54968756e-02, 6.50521303e-19,\n",
       "        4.33680869e-19, 6.05649288e-02, 8.78420037e-03, 3.37489243e-02,\n",
       "        2.50975076e-02, 9.20974555e-03, 8.34012222e-03, 2.16840434e-19,\n",
       "        3.61347242e-02, 8.89228831e-04, 3.20875576e-04, 5.00464722e-02,\n",
       "        1.16497079e-04, 1.03512916e-03, 2.71730760e-04, 3.05130578e-02,\n",
       "        8.67361738e-19, 6.50521303e-19, 2.43717433e-02, 7.84877241e-02,\n",
       "        2.37252571e-02, 2.67756582e-03, 4.32137346e-03, 1.93822019e-02,\n",
       "        5.42821447e-04, 1.03833534e-04, 2.83447247e-02, 1.95199476e-04,\n",
       "        2.67805807e-02, 1.40994306e-02, 9.24971658e-04, 4.98397043e-04,\n",
       "        1.71056893e-02, 2.16840434e-19, 6.47501600e-03, 1.00000000e-01,\n",
       "        4.79833289e-03, 1.96959921e-02, 4.29246770e-04, 4.50047695e-05,\n",
       "        1.00000000e-01, 9.69675290e-03, 6.32808175e-04, 3.40576437e-04,\n",
       "        9.97684914e-02, 2.16840434e-19, 8.67361738e-19, 1.73472348e-18,\n",
       "        1.73472348e-18, 5.74908661e-03, 2.16840434e-19, 1.37409006e-02,\n",
       "        4.50877536e-03, 8.91632676e-04, 8.69587008e-03, 1.96262983e-02,\n",
       "        8.40169829e-04, 3.38265248e-02, 8.21002194e-04, 5.14143634e-04,\n",
       "        5.66150273e-03, 2.90348987e-02, 1.73472348e-18, 7.98366445e-04,\n",
       "        1.00000000e-01, 8.67361738e-19, 9.19152549e-03, 5.65016028e-02,\n",
       "        1.13651511e-03, 3.68703710e-02, 9.82296566e-02, 5.00501833e-03,\n",
       "        6.34283647e-02, 7.18619168e-03, 7.91924400e-02, 1.85857925e-02,\n",
       "        1.73472348e-18, 7.56236985e-03, 7.75202343e-04, 1.66399754e-03,\n",
       "        1.00000000e-01, 4.34562119e-02, 5.19613063e-04, 5.37786813e-04,\n",
       "        3.88630173e-02, 8.02225643e-03, 1.00000000e-01, 4.36502458e-04,\n",
       "        1.25407569e-02, 2.37424687e-02, 5.94038273e-02, 2.03944654e-03,\n",
       "        2.40527449e-03, 8.36882425e-02, 2.08998012e-02, 6.07125769e-02,\n",
       "        4.99501325e-02, 3.82632743e-03, 5.34726612e-04, 2.10948666e-02,\n",
       "        5.80074697e-04, 8.91518075e-02, 1.14546271e-02, 5.91092673e-03,\n",
       "        8.67361738e-19, 7.38199554e-04, 9.91725325e-02, 5.50900188e-02,\n",
       "        3.39080734e-02, 6.66522113e-02, 7.35840944e-02, 4.09958158e-04,\n",
       "        7.96809352e-02, 1.52195100e-03, 2.84198986e-02, 1.01630211e-02,\n",
       "        5.45802810e-04, 2.42042579e-03, 5.26695801e-03, 9.98422907e-03,\n",
       "        2.49916647e-02, 1.44697932e-02, 1.58828012e-02, 3.70023906e-02,\n",
       "        6.57105724e-04, 2.16840434e-19, 9.70220736e-03, 1.06845777e-02,\n",
       "        3.99343839e-02, 6.62523416e-02, 2.13832838e-03, 6.32927726e-03,\n",
       "        1.77262961e-05, 1.73472348e-18, 1.65555318e-03, 7.72102657e-03,\n",
       "        1.85603096e-02, 1.00000000e-01, 1.46510791e-04, 3.25260652e-18,\n",
       "        4.12000764e-03, 8.67361738e-19, 3.67941087e-04, 8.49349327e-02,\n",
       "        8.75840539e-05, 5.58464097e-02, 2.11841374e-02, 7.57324722e-04,\n",
       "        1.00000000e-01, 2.79739193e-02, 1.15066779e-02, 1.00000000e-01,\n",
       "        1.73472348e-18, 3.86814693e-02, 2.57107189e-02, 3.50336651e-04,\n",
       "        1.33026297e-03, 1.18815401e-02, 2.16840434e-19, 3.19472271e-02,\n",
       "        7.90660800e-03, 1.42381835e-03, 6.33159389e-02, 7.67629739e-04,\n",
       "        1.42596664e-02, 5.82616684e-04, 4.33680869e-19, 1.48803275e-02,\n",
       "        4.40048254e-03, 6.71980909e-02, 6.67663422e-02, 1.00000000e-01,\n",
       "        7.28867261e-04, 1.00000000e-01, 7.07978361e-04, 1.93063159e-02,\n",
       "        2.15264153e-04, 3.65447061e-02, 9.19247967e-03, 2.89669558e-03,\n",
       "        3.15058057e-03, 2.04387609e-02, 1.18018672e-02, 5.59890494e-04,\n",
       "        9.90529917e-04, 8.50370649e-03, 7.99126834e-04, 5.44387105e-02,\n",
       "        6.69368835e-04, 9.87548167e-03, 9.98883536e-03, 1.20404711e-03,\n",
       "        2.60208521e-18, 1.30465315e-02, 1.03419789e-02, 1.00000000e-01,\n",
       "        4.66147356e-02, 5.40898027e-03, 2.55899728e-03, 2.34270432e-03,\n",
       "        1.35711923e-02, 3.23113156e-02, 1.62164168e-02, 8.95084131e-03,\n",
       "        4.33680869e-19, 2.83345033e-02, 8.26255682e-04, 1.37242456e-02,\n",
       "        7.53905501e-03, 5.92427463e-03, 1.72039386e-02, 3.40793801e-03,\n",
       "        1.40692814e-02, 1.00000000e-01, 9.90341979e-03, 5.81279762e-03,\n",
       "        3.60628451e-04, 5.62767239e-02, 1.34068807e-02, 8.09533597e-04,\n",
       "        1.33842225e-02, 1.35027819e-02, 5.58468160e-02, 4.33680869e-19,\n",
       "        1.00000000e-01, 6.22340024e-03, 9.85156705e-04, 1.00000000e-01,\n",
       "        4.85375433e-04, 5.65399638e-03, 4.33680869e-19, 3.32123516e-03,\n",
       "        1.00000000e-01, 7.70829524e-02, 8.41948475e-03, 6.15411157e-02,\n",
       "        2.13637881e-03, 1.46074282e-04, 7.04560485e-02, 2.64620624e-02,\n",
       "        1.29443361e-02, 9.41269655e-03, 3.68628739e-18, 1.24224357e-04,\n",
       "        1.00000000e-01, 9.96622864e-02, 3.86044444e-02, 4.73528123e-04,\n",
       "        8.36126623e-02, 1.30104261e-18, 2.27273203e-02, 6.30129217e-04,\n",
       "        1.63354111e-02, 1.73472348e-18, 4.91554493e-04, 2.45503309e-03,\n",
       "        1.73472348e-18, 1.98407287e-02, 7.16652709e-03, 2.37089434e-03,\n",
       "        1.00000000e-01, 1.51788304e-18, 1.00000000e-01, 3.37148843e-04,\n",
       "        5.61178908e-03, 8.85308656e-03, 2.60208521e-18, 9.33497170e-02,\n",
       "        2.20056926e-02, 2.95718327e-02, 7.95209372e-03, 1.18394971e-03,\n",
       "        2.20157154e-02, 8.64607923e-04, 9.94358028e-02, 1.62155076e-02,\n",
       "        3.29221557e-03, 5.80184965e-03, 6.58986230e-03, 4.96296153e-02,\n",
       "        3.23522580e-02, 6.46334256e-04, 6.27454566e-04, 4.33680869e-18,\n",
       "        2.67660902e-04, 7.80877681e-03, 8.96557985e-04, 2.30098199e-02,\n",
       "        2.63416120e-04, 3.01650483e-04, 5.67733686e-04, 1.00000000e-01,\n",
       "        4.20629755e-02, 2.50463675e-02, 6.93889390e-18, 2.15084954e-02,\n",
       "        1.52620419e-02, 1.04143165e-02, 7.05797679e-02, 2.61842009e-02,\n",
       "        2.16840434e-19, 6.94834174e-03, 7.49453355e-03, 1.64135197e-04,\n",
       "        1.00000000e-01, 5.21441443e-02, 5.67308656e-02, 2.56027003e-04,\n",
       "        1.00000000e-01, 5.63785130e-18, 1.73472348e-18, 7.91445485e-04,\n",
       "        5.12191124e-04, 9.78458415e-05, 8.57398776e-02, 7.01611885e-04,\n",
       "        6.44797660e-05, 8.67361738e-19, 7.94704339e-04, 3.49090463e-02,\n",
       "        1.24183754e-02, 3.47834655e-02, 2.01568007e-02, 5.14827085e-02,\n",
       "        1.37921551e-02, 4.23815936e-02, 3.21965497e-02, 2.45718179e-02,\n",
       "        8.67361738e-19, 5.17299449e-07, 7.33926673e-03, 8.67361738e-19,\n",
       "        1.56785760e-04, 3.08368274e-02, 6.23804955e-04, 6.85191920e-03,\n",
       "        2.99991144e-02, 8.51877616e-04, 5.00867457e-03, 4.07557368e-02,\n",
       "        1.84301070e-03, 1.52374630e-03, 1.00000000e-01, 2.16840434e-19,\n",
       "        6.64876096e-02, 2.69763454e-03, 2.30374042e-03, 2.59643262e-02,\n",
       "        5.88678873e-04, 7.39713636e-04, 3.38080435e-02, 9.74393832e-03,\n",
       "        1.44333437e-02, 1.00000000e-01, 4.09744075e-02, 2.04225867e-03,\n",
       "        2.16972844e-02, 6.03200598e-04, 3.89464069e-03, 1.61045493e-02,\n",
       "        2.77412444e-03, 2.41262171e-02, 2.70156561e-04, 9.01815460e-05,\n",
       "        9.55883120e-02, 4.44554242e-06, 7.52710626e-03, 9.00662487e-02,\n",
       "        6.95515296e-05, 1.00000000e-01, 1.00000000e-01, 7.87633483e-04,\n",
       "        6.81209061e-02, 2.07036010e-02, 9.95112727e-02, 5.40049229e-03,\n",
       "        3.71369596e-02, 4.41918484e-03, 4.40284601e-04, 9.83919430e-03,\n",
       "        8.24192156e-03, 2.02177847e-02, 2.66965544e-04, 1.95005315e-02,\n",
       "        2.21011813e-02, 5.56936702e-02, 5.15699378e-02, 2.86177254e-04,\n",
       "        2.56127529e-02, 8.07295222e-03, 7.50544246e-04, 4.31239698e-02,\n",
       "        4.82137722e-02, 8.67361738e-19, 2.31170648e-04, 2.30419426e-02,\n",
       "        8.67361738e-19, 1.00000000e-01, 4.35307764e-02, 1.00000000e-01,\n",
       "        7.77202516e-04, 7.47221562e-03, 5.75432091e-02, 5.87606104e-02,\n",
       "        2.41822144e-03, 8.99162541e-03, 1.01417894e-02, 9.99963225e-04,\n",
       "        9.98946827e-02, 2.18034525e-04, 6.60366830e-02, 1.00805007e-04,\n",
       "        7.66704493e-02, 1.33981404e-02, 1.00000000e-01, 4.33680869e-19,\n",
       "        6.07153217e-18, 5.15201125e-03, 1.42131680e-04, 2.16840434e-19,\n",
       "        2.82357299e-04, 3.13392606e-02, 1.00000000e-01, 1.19879256e-04,\n",
       "        8.42815315e-03, 1.20136939e-02, 1.30104261e-18, 9.20746856e-04,\n",
       "        2.73975710e-02, 1.64537255e-02, 3.19295052e-02, 1.04361951e-02,\n",
       "        5.59946576e-04, 1.77835551e-02, 1.99477070e-02, 1.81866807e-02,\n",
       "        4.33680869e-19, 9.45122775e-04, 5.38355770e-02, 1.86904068e-03,\n",
       "        4.96531268e-03, 3.47289950e-04, 8.91767239e-03, 4.51398202e-04,\n",
       "        7.49667188e-04, 1.00607378e-02, 2.57792375e-02, 9.24787705e-02,\n",
       "        4.29584872e-03, 1.06270364e-04, 7.06245908e-03, 9.82859529e-02,\n",
       "        1.00000000e-01, 8.75293034e-04, 1.00000000e-01, 6.89743841e-03,\n",
       "        1.20027161e-02, 8.09762287e-03, 2.44566711e-04, 5.69486696e-04,\n",
       "        5.49467186e-05, 5.72469031e-02, 4.33680869e-19, 4.83738883e-03,\n",
       "        6.08260085e-02, 1.99074882e-04, 1.50409203e-02, 2.60208521e-18,\n",
       "        2.28200420e-04, 7.21278588e-02, 5.91959393e-03, 1.29208625e-03,\n",
       "        1.00000000e-01, 2.01779860e-04, 2.83757401e-04, 2.26238703e-03,\n",
       "        8.65608891e-04, 1.00000000e-01, 3.23684499e-02, 5.51936791e-04,\n",
       "        9.44368354e-02, 2.96138872e-05, 2.99663836e-02, 7.98754627e-03,\n",
       "        1.00000000e-01, 1.00000000e-01, 3.04306580e-02, 1.67722759e-02,\n",
       "        5.12665247e-04, 2.50664970e-04, 4.57447847e-05, 2.98438883e-02,\n",
       "        5.80200985e-04, 2.64761467e-02, 5.92566878e-04, 7.21568454e-02,\n",
       "        6.04820108e-03, 1.99579257e-02, 1.29183823e-04, 4.25262217e-02,\n",
       "        9.68100063e-04, 1.64412551e-02, 2.49212990e-04, 2.11702113e-04,\n",
       "        6.14371790e-03, 7.45736098e-04, 6.72227537e-04, 3.37442780e-02,\n",
       "        2.78065591e-02, 2.38722157e-03, 8.67522019e-03, 4.56967791e-02,\n",
       "        1.73472348e-18, 8.06766755e-03, 4.92607540e-02, 5.78915432e-03,\n",
       "        2.27193529e-04, 9.98662362e-04, 5.41840753e-02, 1.30104261e-18,\n",
       "        8.18114272e-03, 4.38656109e-03, 3.74014998e-03, 4.33680869e-19,\n",
       "        6.50838103e-05, 1.65702231e-04, 9.21774479e-04, 4.33680869e-19,\n",
       "        2.38524478e-18, 5.67402960e-02, 8.11058888e-02, 4.33680869e-19,\n",
       "        7.41441029e-03, 4.82586691e-02, 1.00000000e-01, 7.64633291e-04,\n",
       "        7.72347603e-03, 3.69631099e-02, 1.85987194e-02, 1.00000000e-01,\n",
       "        4.26295031e-04, 1.00000000e-01, 7.02158674e-04, 2.16840434e-18,\n",
       "        1.44653629e-04, 3.66480103e-04, 3.42569320e-04, 8.17911979e-04,\n",
       "        4.91577004e-02, 2.62226418e-02, 9.51815446e-04, 2.31052989e-03,\n",
       "        4.95340459e-03, 2.83424406e-02, 1.00000000e-01, 1.43030151e-05,\n",
       "        5.29627541e-02, 6.02123541e-04, 7.47054045e-04, 4.33680869e-19,\n",
       "        1.00000000e-01, 2.60973925e-02, 8.96554303e-04, 2.34474005e-02,\n",
       "        9.41771697e-04, 4.62932551e-02, 5.83699343e-05, 7.31787955e-04,\n",
       "        4.33680869e-19, 2.28469069e-02, 5.32814343e-03, 8.74239641e-04,\n",
       "        3.46944695e-18, 6.77281856e-03, 1.08613073e-02, 5.44684003e-04,\n",
       "        8.69876183e-03, 6.88446153e-03, 1.97361370e-02, 6.31934375e-04]),\n",
       " 'w': array([ 0.00874194,  0.01525562,  0.05899199, ..., -0.08386229,\n",
       "        -0.00422915,  0.06285207])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the model\n",
    "import pickle\n",
    "def storeData(var_, file_):       \n",
    "    # Its important to use binary mode \n",
    "    dbfile = open(file_, 'ab') \n",
    "    # source, destination \n",
    "    pickle.dump(var_, dbfile)                      \n",
    "    dbfile.close() \n",
    "  \n",
    "def loadData(file_): \n",
    "    # for reading also binary mode is important \n",
    "    dbfile = open(file_, 'rb')      \n",
    "    return pickle.load(dbfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeData(model, os.path.join('Data', 'spamDetector.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.83\n"
     ]
    }
   ],
   "source": [
    "# Compute the training accuracy\n",
    "p = utils.svmPredict(model, X)\n",
    "\n",
    "print('Training Accuracy: %.2f' % (np.mean(p == y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to load the test set and compute the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the trained Linear SVM on a test set ...\n",
      "Test Accuracy: 98.90\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "# You will have Xtest, ytest in your environment\n",
    "data = loadmat(os.path.join('Data', 'spamTest.mat'))\n",
    "Xtest, ytest = data['Xtest'].astype(float), data['ytest'][:, 0]\n",
    "\n",
    "print('Evaluating the trained Linear SVM on a test set ...')\n",
    "p = utils.svmPredict(model, Xtest)\n",
    "\n",
    "print('Test Accuracy: %.2f' % (np.mean(p == ytest) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top predictors of spam:\n",
      "word            weight         \n",
      "----            ------\n",
      "our             0.50\n",
      "click           0.46\n",
      "remov           0.42\n",
      "guarante        0.38\n",
      "visit           0.37\n",
      "basenumb        0.35\n",
      "dollar          0.33\n",
      "will            0.27\n",
      "price           0.27\n",
      "pleas           0.26\n",
      "most            0.26\n",
      "nbsp            0.25\n",
      "lo              0.24\n",
      "se              0.24\n",
      "dollarnumb      0.24\n"
     ]
    }
   ],
   "source": [
    "# Sort the weights and obtin the vocabulary list\n",
    "# NOTE some words have the same weights, \n",
    "# so their order might be different than in the text above\n",
    "idx = np.argsort(model['w'])\n",
    "top_idx = idx[-15:][::-1]\n",
    "vocabList = utils.getVocabList()\n",
    "\n",
    "print('Top predictors of spam:')\n",
    "print('%-15s %-15s' % ('word', 'weight'))\n",
    "print('----' + ' '*12 + '------')\n",
    "for word, w in zip(np.array(vocabList)[top_idx], model['w'][top_idx]):\n",
    "    print('%-15s %0.2f' % (word, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Data\\amway.txt\n",
      "Spam Classification: spam\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join('Data', 'amway.txt')\n",
    "\n",
    "with open(filename) as fid:\n",
    "    file_contents = fid.read()\n",
    "\n",
    "word_indices = processEmail(file_contents, verbose=False)\n",
    "x = emailFeatures(word_indices)\n",
    "p = utils.svmPredict(model, x)\n",
    "\n",
    "print('\\nProcessed %s\\nSpam Classification: %s' % (filename, 'spam' if p else 'not spam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there, how are you.\\n\\nAre you interested in Amway sales program?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
